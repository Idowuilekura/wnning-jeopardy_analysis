{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Guided Project Winning Jeopardy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Jeopardy is a popular TV show in the US where participants answer questions to win money.It has been eunning for a few decades, and is a major force in popular culture.In this project we will the various ways anyone can have an edge to win. The dataset we willbe working with is called ```jeopardy.csv```, and contains 20000 rows from the beginning of a full dataset of jeopardy questions, which can be downloaded [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "jeopardy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the dataset repesents a single question on a single episode of jeopardy. Here are explanations of each column:\n",
    "- Show Number -- the Jeopardy episode number of the show this question was in.\n",
    "- Air Date -- the date the episode aired.\n",
    "- Round -- the round of jeopardy that the question was asked in. Jeopardy has several rounds as each episode progresses.\n",
    "- Category -- the category of the question\n",
    "- Value -- the number of dollars answwering the question correctly is worth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing spaces from columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy.columns = ['Show Number','Air Date','Round','Category','Value','Question','Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the jeopardy questions and answers values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start doing analysis on the Jeopardy questions, we will need to normalize all of the text columns ( the Question and Answer columns).This is done to ensure that there are no discreprancies due to capitalization and punctuation. We will write a function that takes in a string, convert the string to lowercase, remove all punctuation in the string and return the string.We will use the apply function to apply the function to question column, answer column. We will write another function to help normalize the value column, we  write a function that takes in a string, remove anypuctuation in the string, convert the string to an integer,if the conversion has an error assign 0i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# writing the function that will perform the operation\n",
    "import re \n",
    "def normalize(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub(\"[^A-Za-z0-9\\s]\",\"\",string)\n",
    "    return string\n",
    "def normalize_values(string):\n",
    "    string = re.sub(\"[^A-Za-z0-9\\s]\",\"\",string)\n",
    "    try:\n",
    "        string =int(string)\n",
    "    except Exception:\n",
    "        string =0\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_values'] = jeopardy['Value'].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    for the last 8 years of his life galileo was u...\n",
       "1    no 2 1912 olympian football star at carlisle i...\n",
       "Name: clean_question, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_question'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    copernicus\n",
       "1    jim thorpe\n",
       "Name: clean_answer, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_answer'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "Name: clean_values, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_values'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2004-12-31\n",
       "1   2004-12-31\n",
       "2   2004-12-31\n",
       "3   2004-12-31\n",
       "4   2004-12-31\n",
       "Name: Air Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['Air Date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out whether to study past questions, study general knowledge, or not study it at all,it would be helpful to figure out two things:\n",
    "- How often the answer is deducible from the question.\n",
    "- How often new questions are repeats of older questions.\n",
    "\n",
    "The second answer can be answered by seeing how often complex words (>6 characters) reoccur. The first answer can be answered by seeing how many times words in the answer also occur in the question. We will work with the first question and come bak to the second later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will write a function that takes in a row in jeopardy, as a series. It should:\n",
    "- Split the clean_answer column around spaces and assign to the variable split_answer\n",
    "- split the clean_question column around spaces and assign to the variable split_question.\n",
    "- Create a variable called match_count and set it to 0\n",
    "- If 'the' is in the split_answer remove i using the remove method on lits. The is commonly found in answers and questons, but dosen't have any meaningful use in finding the answer.\n",
    "- If the lenght of split_answer is 0, return 0. This prevents a division by zero error later.\n",
    "- Loop through each item in split_answer and see if it occurs in split_question. If it does add 1 to match_count\n",
    "- Divide match_count by the legth of split_answer and return the result.\n",
    "\n",
    "- Count how many times terms in clean_answer occur in clean_question\n",
    "- Use the Pandas dataframe.apply method to apply the function to each row in jeopardy\n",
    "- pass the axis = 1 argument to apply the function across each row.\n",
    "- Assign the result to the answer_in_question column\n",
    "- Find the mean of the answer_in_question column using the mean method on series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_rows(row):\n",
    "    split_clean_answer = row['clean_answer'].split(\" \")\n",
    "    split_clean_question = row['clean_question'].split(\" \")\n",
    "    match_count = 0\n",
    "    if 'the' in split_clean_answer:\n",
    "        split_clean_answer.remove('the')\n",
    "    if len(split_clean_answer) ==0:\n",
    "        return 0\n",
    "    if len(split_clean_answer)>0:\n",
    "        for word in split_clean_answer:\n",
    "            if word in split_clean_question:\n",
    "                match_count += 1\n",
    "    return match_count/len(split_clean_answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['answer_in_question'] = jeopardy.apply(match_rows,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06049325706933587"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the computed mean of words that occured in both clean_answer and cleaned question is about 0.06 that is about 6%. This is quite low and seems that it is rare to find words that repeats itself in the question "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us say that we want to invetigate how often new questions are repeats of older ones. We can not completely answer this, because we only have about 10% of the full Jeopardy question dataset,but we can investigate it at least. \n",
    "- To do this we will sort jeopardy in order of ascending air date\n",
    "- Maintain a set called terms_used that will be empty initially.\n",
    "- Iterate through each row of jeopardy\n",
    "- Split clean_question into words, remove any words shorter than 6 characters, check if word occurs in term_used\n",
    "- If it does we increase a counter \n",
    "- add each word to terms_used.\n",
    "This will enable us to check if the terms in questions have been used previously or not. Only looking at words with six or more characters enables us to filter out words like the and then, which are commonly used but do not tell us a lot about a question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7019788296638052"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "jeopardy = jeopardy.sort_values('Air Date')\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    split_question = [q for q in split_question if len(q)>5]\n",
    "    match_count=0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question)>0:\n",
    "        calculated_match = match_count/len(split_question)\n",
    "    question_overlap.append(calculated_match)\n",
    "\n",
    "jeopardy['question_overlap'] = question_overlap\n",
    "jeopardy['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we could see that there are about 71% of questions overlap i.e we had more question that were repeated\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us say we only want to study questions that pertain to high value questions instead of low value questions. This will help  us to earn more money when we are on Jeopardy.\n",
    "\n",
    "We can actually figure out which terms correspond to high-value questions using a chi-squared test. We will first need to narrow down the questions into two categories:\n",
    "- Low value -- Any row where value is less than 800\n",
    "- High value-- Any row where value is greater than 800\n",
    "- Find the perecentage of questions the word occur in,\n",
    "- Based on the percentage of questions the word occurs in, find the expected counts.\n",
    "- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def high_value(row): # assign 1 of clean_values is >800 else 0\n",
    "    if row['clean_values'] >800:\n",
    "        value =1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "jeopardy['high_value'] = jeopardy.apply(high_value,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def high_low_count(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index,rows in jeopardy.iterrows():\n",
    "        split_question = rows['clean_question'].split(\" \")\n",
    "        if word in split_question:\n",
    "            if rows['high_value'] ==1:\n",
    "                high_count +=1 \n",
    "            else:\n",
    "                low_count += 1\n",
    "    return low_count,high_count\n",
    "comparison_terms = [np.random.choice(list(terms_used)) for i in range(10)]\n",
    "observed_expected = []\n",
    "#print(comparison_terms)\n",
    "for i in comparison_terms:\n",
    "    observed_expected.append(high_low_count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- above we created a function that takes in a row from a dataframe,\n",
    "- if the clean_value column is greater than 800, assign 1 to value\n",
    "- otherwise assign 0 to value\n",
    "- return value\n",
    "Determine which questions are high and low\n",
    "- used the pandas dataframe.appply method to apply the fuction to each row in jeopardy\n",
    "- pass the axis=1 argumant to apply the function across each row\n",
    "- Assign the result to the high_value column\n",
    "We created a function that takes in a word,\n",
    "- Assigned 0 to low_count\n",
    "- Assigned 0 to high_count\n",
    "- Looped through each row in jeopardt using the itterows method\n",
    "- split the clean_question column on the space character (\" \")\n",
    "- if the is in the split question:\n",
    "= if the high_value column is 1add 1 to high_count\n",
    "- else add 1 to low_count\n",
    "- Returns high_count and low_count.\n",
    "- Randomly pick ten elements of terms_used and append them to a list called comparison_terms\n",
    "- created an empty list called observed_expected\n",
    "- Looped through each term in comparison_term \n",
    "- ran the function on the term to get the igh value and low value counts\n",
    "- Append the result of running the function( which will be a list) to observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0),\n",
       " (1, 0),\n",
       " (2, 3),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (2, 0),\n",
       " (31, 15),\n",
       " (3, 0),\n",
       " (1, 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the observed counts fro a few terms,we can ccompute the expected counts and the chi-squared value\n",
    "\n",
    "- We will find the number of rows in jeopardy where high_value is 1 and assign to high_value_count\n",
    "- find the number of rows in jeopardy where high_value is 0 and assign to low_value_count\n",
    "- create an empty list caled chi_squared\n",
    "- Loop through each list called chi_squared\n",
    "- Add up both items in the list(high and low counts) to get the total count, assign to total.\n",
    "- Divide total by the number of rows in jeopardy to get the proportion across the dataset.Asign to total_prop\n",
    "- Multiply total_prop by high_value_count to get the expected term count for high value rows\n",
    "- Multiply total_prop by low_value_count to get the expected term count for low value rows\n",
    "- use the scipy.stats.chisquare function to compute the chi-squared value and p-value given the expected and observed counts\n",
    "- Append the result to 'chi_squared'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "high_value_count = len(jeopardy[jeopardy['high_value']==1])\n",
    "low_value_count = len(jeopardy[jeopardy['high_value']==0])\n",
    "chi_squared = []\n",
    "for i in observed_expected:\n",
    "    total = sum(list(i))\n",
    "    total_prop = total/len(jeopardy)\n",
    "    expected_high_count = total_prop * high_value_count\n",
    "    expected_low_count = total_prop * low_value_count\n",
    "    observed = [i[0],i[1]]\n",
    "    expected = [expected_high_count,expected_low_count]\n",
    "    chisquare_hello = chisquare(observed,expected)\n",
    "    chi_squared.append(chisquare_hello)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.3137668167849311, pvalue=0.5753778622944691),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=4.97558423439135, pvalue=0.025707519787911092),\n",
       " Power_divergenceResult(statistic=33.72195358703462, pvalue=6.357910423575818e-09),\n",
       " Power_divergenceResult(statistic=7.463376351587025, pvalue=0.006296679668748999),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chisquared result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the chisquared result we could see that most of the p_values above the 0.05 threshold to reject any statistical significance,so it seems there is no statistical difference among the expected and observed high and low values on the premises of low frequency.\n",
    "\n",
    "This shows that the high and low are different and they do not depend on each other to occur "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
